{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Airflow Metadata - DAGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_airflow_dag_list.py\n",
    "\n",
    "from airflow import settings\n",
    "from airflow.models import DagModel\n",
    "from sqlalchemy.orm import Session\n",
    "\n",
    "import os\n",
    "from airflow import DAG\n",
    "from airflow.operators.python_operator import PythonOperator\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "DAG_NAME = 'get_dag_list'\n",
    "dag_args= {\n",
    "    'owner': 'rho715@wavve.com',\n",
    "    'depends_on_past': False,\n",
    "    'start_date': datetime.today() - timedelta(days=1),\n",
    "    'email_on_failure': False,\n",
    "    'email_on_retry': False,\n",
    "    'retries': 0,\n",
    "    #'on_failure_callback': alert.slack_fail_alert\n",
    "}\n",
    "\n",
    "# cron_schedule = None\n",
    "cron_schedule = '55 7 * * *'\n",
    "dag = DAG(DAG_NAME, catchup=False, default_args=dag_args, schedule_interval=cron_schedule, tags=['test'], is_paused_upon_creation=True)\n",
    "\n",
    "def my_task_run():\n",
    "    # Open the file for writing\n",
    "    with open(\"/opt/airflow/data/dag_list.txt\",\"w\") as f:\n",
    "        session = Session(bind=settings.engine)\n",
    "        dags = session.query(DagModel).filter(DagModel.is_active == True).all()\n",
    "        print(\"Running my task at 8am every day!\")\n",
    "        print(os.getcwd())\n",
    "\n",
    "        # Write the header to the file\n",
    "        f.write(\"DAG ID, Schedule Interval \\n\")\n",
    "\n",
    "        for dag in dags:\n",
    "            # Write the DAG information to the file\n",
    "            f.write(f\"DAG ID: {dag.dag_id}, Schedule Interval: {dag.schedule_interval}\")\n",
    "\n",
    "        session.close()\n",
    "    # Close the file after the loop has completed\n",
    "\n",
    "# Close the Session\n",
    "\n",
    "task = PythonOperator(\n",
    "    task_id=\"my_task\",\n",
    "    python_callable=my_task_run,\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "# Add the operator to the DAG using the DAG.add_task method\n",
    "task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS s3 접근"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from io import BytesIO\n",
    "import gzip\n",
    "\n",
    "# Set the bucket and key names\n",
    "bucket_name = 'my-s3-bucket'\n",
    "key_name = 'my-gzip-file.gz'\n",
    "\n",
    "# Connect to the S3 service\n",
    "client = boto3.client('s3')\n",
    "\n",
    "# Retrieve the gzip-compressed file from the S3 bucket\n",
    "response = client.get_object(Bucket=bucket_name, Key=key_name)\n",
    "\n",
    "# Decompress the gzip-compressed file\n",
    "data = BytesIO(response['Body'].read())\n",
    "gzip_file = gzip.GzipFile(fileobj=data)\n",
    "content = gzip_file.read()\n",
    "\n",
    "# Write the decompressed content to an output file\n",
    "with open('output_file.txt', 'w') as f:\n",
    "    f.write(content.decode('utf-8'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1 (v3.11.1:a7a450f84a, Dec  6 2022, 15:24:06) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
